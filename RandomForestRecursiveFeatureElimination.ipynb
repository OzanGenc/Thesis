{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import collections\n",
    "\n",
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\Users\\Comp_Imaging_1\\Desktop\\Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('SPECT.xlsx', sheet_name = 'Sheet1')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NA\n",
    "data = data.dropna(axis = 1, thresh = round((0.5)*data.shape[0])) #removing features existing in less than half of the samples \n",
    "data = data.dropna(axis = 0, thresh = round((0.5)*data.shape[1])) #removing samples having less than half of the features \n",
    "data = data.fillna(0) #filling missing values with zeroes\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def correlation(dataset, threshold):\n",
    "#    col_corr = set()  # Set of all the names of correlated columns\n",
    "#    corr_matrix = dataset.corr()\n",
    "#    for i in range(len(corr_matrix.columns)):\n",
    "#        for j in range(i):\n",
    "#            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "#                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "#                col_corr.add(colname)\n",
    "#    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change number of selected features\n",
    "number_of_selected_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection Algorithms\n",
    "fs1 = RFE(LinearSVC(), n_features_to_select=number_of_selected_features, verbose=2)\n",
    "fs2 = RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=number_of_selected_features, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipelines\n",
    "\n",
    "#pipeline4\n",
    "pipe4 = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('fs', fs2)])\n",
    "\n",
    "gs = pipe4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking training set model performance for detecting underfitting\n",
    "start = time.time()\n",
    "gs = gs.fit(np.array(data.drop(labels=['grup'], axis=1)), data['grup'])\n",
    "\n",
    "training_pred = gs.predict(np.array(data.drop(labels=['grup'], axis=1)))\n",
    "end = time.time()\n",
    "print(confusion_matrix(data['grup'],training_pred))\n",
    "print('Computation Time:',end - start)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimated_Time = ((end - start)*data.shape[0])\n",
    "print('Estimated Time:',Estimated_Time/60,'min','or',Estimated_Time/3600,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Program start to run at',time.localtime())\n",
    "pred=[]\n",
    "response=[]\n",
    "selectedfeatures=[]\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    test = data.iloc[[i]] \n",
    "    train = data.drop(data.index[i])\n",
    "    \n",
    " #   corr_features = correlation(train.drop(labels=['grup'], axis=1), 0.9)\n",
    " #   print('correlated features: ', len(set(corr_features)))\n",
    "    \n",
    "    \n",
    "    # run gridearch\n",
    "    gs = gs.fit(np.array(train.drop(labels=['grup'], axis=1)), train['grup'])\n",
    "    pred.append(int(gs.predict(np.array(test.drop(labels=['grup'], axis=1)))))\n",
    "    \n",
    "    # storing true labels\n",
    "    response.append(int(test['grup']))\n",
    "    # storing the selected features in a list\n",
    "    selectedfeatures.append(tuple(gs.steps[1][1].get_support(indices=True)))          #for RF-RFE\n",
    "    \n",
    "print(pred)\n",
    "print(response)\n",
    " \n",
    "\n",
    "counter=collections.Counter(selectedfeatures)\n",
    "\n",
    "print('Most Common Selected Features:',np.array(counter.most_common))    #change according to number of selected features\n",
    "\n",
    "end = time.time()\n",
    "print('Computation Time:',(end - start)/60,'min')\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Most Common Selected Features list above. As an example, (0,1,2):48 means that features having indices 0,1,2\n",
    "#are selected 48 times out of 48+26=74 trials. Names of these features can be learned by writing index values below in \n",
    "#df = data.drop(labels=['grup'], axis=1).iloc[:,[0, 1, 2 <---write indices as here]]. \n",
    "\n",
    "\n",
    "df = data.drop(labels=['grup'], axis=1).iloc[:,[0, 1, 2]]   #change indices \n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
